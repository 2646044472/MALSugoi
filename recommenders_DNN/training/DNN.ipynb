{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5960edbe",
   "metadata": {},
   "source": [
    "### Process data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4fecc1-f828-4942-98e8-f381073e9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a451aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# run this block once only\n",
    "project_root = os.path.abspath(\"../../\")  # 根据文件层级调整路径\n",
    "os.chdir(project_root)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2286ecb",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0b69b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Users: 100%|██████████| 528/528 [00:14<00:00, 36.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 X 形状: torch.Size([12320, 162]), y 形状: torch.Size([12320])\n",
      "测试集 X 形状: torch.Size([3080, 162]), y 形状: torch.Size([3080])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 检查是否可以使用 CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. 加载数据\n",
    "anime_data = pd.read_csv('./data/anime_info/anime_data.csv')\n",
    "user_ratings = pd.read_csv('./data/user_animelist/anime_info.csv')\n",
    "\n",
    "# 清理数据\n",
    "anime_data['score'] = anime_data['score'].replace('-', np.nan).astype(float)  # 如果有缺失值处理\n",
    "user_ratings['rating'] = user_ratings['rating'].replace('-', np.nan).astype(float)\n",
    "\n",
    "# 去掉没有评分的条目\n",
    "user_ratings = user_ratings.dropna(subset=['rating'])\n",
    "\n",
    "# 格式化数值\n",
    "anime_data['members'] = anime_data['members'].str.replace(',', '').astype(float)\n",
    "anime_data['favorites'] = anime_data['favorites'].str.replace(',', '').astype(float)\n",
    "anime_data['popularity'] = anime_data['popularity'].str.replace('#', '').astype(float)\n",
    "anime_data['ranked'] = anime_data['ranked'].str.replace('#', '').astype(float)\n",
    "\n",
    "# 2. 提取番剧特征\n",
    "def preprocess_genres(genres_series):\n",
    "    \"\"\"将 genres 列转为 multi-hot 编码\"\"\"\n",
    "    genres_series = genres_series.fillna('')  # 填充空值\n",
    "    genres_list = genres_series.str.split(', ')\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    genres_encoded = mlb.fit_transform(genres_list)\n",
    "    return genres_encoded, mlb.classes_\n",
    "\n",
    "# 处理 genres 列\n",
    "genres_encoded, genres_classes = preprocess_genres(anime_data['genres'])\n",
    "\n",
    "# 将 genres 编码加入 anime_data\n",
    "anime_data = anime_data.join(pd.DataFrame(genres_encoded, columns=genres_classes))\n",
    "\n",
    "# 特征列\n",
    "anime_features = ['score', 'ranked', 'popularity', 'members', 'favorites'] + list(genres_classes)\n",
    "\n",
    "# 标准化数值特征\n",
    "scaler = StandardScaler()\n",
    "anime_data[anime_features] = scaler.fit_transform(anime_data[anime_features])\n",
    "\n",
    "# 将特征从 DataFrame 转换为 GPU 上的张量\n",
    "anime_tensor = torch.tensor(anime_data[anime_features].values, dtype=torch.float32).to(device)\n",
    "\n",
    "# 将标题映射到 GPU 上\n",
    "titles = anime_data['title'].values\n",
    "title_to_index = {title: idx for idx, title in enumerate(titles)}\n",
    "\n",
    "# 3. 构建用户-番剧评分的训练数据\n",
    "def construct_training_data(merged_data, anime_tensor, title_to_index):\n",
    "    \"\"\"\n",
    "    构建训练数据 (X, y)，并将所有操作移到 GPU\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    grouped = merged_data.groupby('username')  # 按用户名分组\n",
    "    \n",
    "    # 使用 tqdm 包装分组数据，显示进度条\n",
    "    for username, group in tqdm(grouped, desc=\"Processing Users\", total=len(grouped)):\n",
    "        user_ratings = group[['anime', 'rating']].set_index('anime')['rating'].to_dict()  # 用户的评分历史\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            # 当前目标番剧\n",
    "            target_anime = row['anime']\n",
    "            target_rating = row['rating']\n",
    "            \n",
    "            # 跳过如果没有评分的目标番剧\n",
    "            if target_anime not in user_ratings:\n",
    "                continue\n",
    "            \n",
    "            # 构建输入特征\n",
    "            user_history = {k: v for k, v in user_ratings.items() if k != target_anime}  # 除去目标番剧的历史\n",
    "            history_features = []\n",
    "            \n",
    "            for anime, rating in user_history.items():\n",
    "                if anime in title_to_index:\n",
    "                    anime_idx = title_to_index[anime]\n",
    "                    anime_feature = anime_tensor[anime_idx]\n",
    "                    history_features.append(anime_feature * rating)  # 特征加权\n",
    "            \n",
    "            # 如果用户历史为空，则跳过\n",
    "            if len(history_features) == 0:\n",
    "                continue\n",
    "            \n",
    "            # 聚合历史特征（例如求平均值）\n",
    "            history_features = torch.stack(history_features).mean(dim=0)\n",
    "            \n",
    "            # 目标番剧的特征\n",
    "            target_idx = title_to_index[target_anime]\n",
    "            target_features = anime_tensor[target_idx]\n",
    "            \n",
    "            # 拼接特征\n",
    "            input_features = torch.cat([history_features, target_features])\n",
    "            \n",
    "            # 添加到训练集\n",
    "            X.append(input_features)\n",
    "            y.append(target_rating)\n",
    "    \n",
    "    return torch.stack(X), torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "# 按照 anime title 合并 user_ratings 和 anime_data\n",
    "merged_data = user_ratings.merge(anime_data, left_on='anime', right_on='title', how='inner')\n",
    "\n",
    "# 构建训练数据\n",
    "X, y = construct_training_data(merged_data, anime_tensor, title_to_index)\n",
    "\n",
    "# 分割训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 转换为 PyTorch 数据集\n",
    "class AnimeDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X  # 已经在 GPU 上，无需再次转换\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# 构建训练和测试数据集\n",
    "train_dataset = AnimeDataset(X_train, y_train)\n",
    "test_dataset = AnimeDataset(X_test, y_test)\n",
    "\n",
    "# 使用 DataLoader 加载数据\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "# 输出数据形状\n",
    "print(f\"训练集 X 形状: {X_train.shape}, y 形状: {y_train.shape}\")\n",
    "print(f\"测试集 X 形状: {X_test.shape}, y 形状: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# 模型定义\n",
    "class AnimeRatingPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=[512, 256, 128], dropout=0.3):\n",
    "        \"\"\"\n",
    "        全连接神经网络，适配输入维度\n",
    "        :param input_size: 输入特征的维度\n",
    "        :param hidden_sizes: 隐藏层每层的神经元数量\n",
    "        :param dropout: Dropout 概率\n",
    "        \"\"\"\n",
    "        super(AnimeRatingPredictor, self).__init__()\n",
    "\n",
    "        # 定义全连接层\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])  # Batch Normalization\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])\n",
    "        \n",
    "        # 输出层\n",
    "        self.output = nn.Linear(hidden_sizes[2], 1)\n",
    "        \n",
    "        # Dropout 层\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入特征\n",
    "        :return: 预测评分，范围 [1, 10]\n",
    "        \"\"\"\n",
    "        # 第一层\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 第二层\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 第三层\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 输出层 (限制范围在 [1, 10])\n",
    "        x = self.output(x)\n",
    "        x = torch.sigmoid(x) * 9 + 1  # 映射到 [1, 10]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b2e02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化设备和模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = X_train.shape[1]  # 输入特征的维度\n",
    "model = AnimeRatingPredictor(input_size=input_size).to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()  # 均方误差损失，用于回归任务\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d943c0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnimeRatingPredictor(\n",
      "  (fc1): Linear(in_features=162, out_features=512, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (output): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/100, Loss: 2.322827648313552\n",
      "Epoch 2/100, Loss: 1.8377453607598735\n",
      "Epoch 3/100, Loss: 1.6978217196588072\n",
      "Epoch 4/100, Loss: 1.6307572067710403\n",
      "Epoch 5/100, Loss: 1.5837603319494218\n",
      "Epoch 6/100, Loss: 1.5447903995069197\n",
      "Epoch 7/100, Loss: 1.5073846881253732\n",
      "Epoch 8/100, Loss: 1.4767901857282213\n",
      "Epoch 9/100, Loss: 1.4620459620199056\n",
      "Epoch 10/100, Loss: 1.4277363984695988\n",
      "Epoch 11/100, Loss: 1.4161338772180785\n",
      "Epoch 12/100, Loss: 1.3783069592683426\n",
      "Epoch 13/100, Loss: 1.3793711455374802\n",
      "Epoch 14/100, Loss: 1.3554270727646782\n",
      "Epoch 15/100, Loss: 1.3450499325218597\n",
      "Epoch 16/100, Loss: 1.3192741645432506\n",
      "Epoch 17/100, Loss: 1.279235652691342\n",
      "Epoch 18/100, Loss: 1.2677369089941903\n",
      "Epoch 19/100, Loss: 1.2603657381522224\n",
      "Epoch 20/100, Loss: 1.2518795617503824\n",
      "Epoch 21/100, Loss: 1.208886466186899\n",
      "Epoch 22/100, Loss: 1.2189872447073151\n",
      "Epoch 23/100, Loss: 1.1940214047160174\n",
      "Epoch 24/100, Loss: 1.1798754961379452\n",
      "Epoch 25/100, Loss: 1.1495497285393235\n",
      "Epoch 26/100, Loss: 1.1381412821730184\n",
      "Epoch 27/100, Loss: 1.1133676449251917\n",
      "Epoch 28/100, Loss: 1.1199788611787589\n",
      "Epoch 29/100, Loss: 1.0913648630053268\n",
      "Epoch 30/100, Loss: 1.0736182409246968\n",
      "Epoch 31/100, Loss: 1.0642980544060623\n",
      "Epoch 32/100, Loss: 1.0573791305635878\n",
      "Epoch 33/100, Loss: 1.04282488507928\n",
      "Epoch 34/100, Loss: 1.051605559074817\n",
      "Epoch 35/100, Loss: 1.005770153641083\n",
      "Epoch 36/100, Loss: 1.006330149779048\n",
      "Epoch 37/100, Loss: 0.9978998674012218\n",
      "Epoch 38/100, Loss: 1.0049425981205362\n",
      "Epoch 39/100, Loss: 0.9899597671365491\n",
      "Epoch 40/100, Loss: 0.9624819502311667\n",
      "Epoch 41/100, Loss: 0.9578711671532745\n",
      "Epoch 42/100, Loss: 0.9410192611303971\n",
      "Epoch 43/100, Loss: 0.9360157872111069\n",
      "Epoch 44/100, Loss: 0.914555155242663\n",
      "Epoch 45/100, Loss: 0.9188013030457373\n",
      "Epoch 46/100, Loss: 0.9039194316752834\n",
      "Epoch 47/100, Loss: 0.9166278202916675\n",
      "Epoch 48/100, Loss: 0.8876922067274083\n",
      "Epoch 49/100, Loss: 0.8808202796031774\n",
      "Epoch 50/100, Loss: 0.8795665539608101\n",
      "Epoch 51/100, Loss: 0.86954580780138\n",
      "Epoch 52/100, Loss: 0.8372435109602973\n",
      "Epoch 53/100, Loss: 0.8646337524288059\n",
      "Epoch 54/100, Loss: 0.8334560724737731\n",
      "Epoch 55/100, Loss: 0.8353086521588459\n",
      "Epoch 56/100, Loss: 0.8407513195060078\n",
      "Epoch 57/100, Loss: 0.8126617986612369\n",
      "Epoch 58/100, Loss: 0.8120012684807258\n",
      "Epoch 59/100, Loss: 0.8047957838816964\n",
      "Epoch 60/100, Loss: 0.8230896797513715\n",
      "Epoch 61/100, Loss: 0.8112777468454034\n",
      "Epoch 62/100, Loss: 0.7980247777669541\n",
      "Epoch 63/100, Loss: 0.7916001714573005\n",
      "Epoch 64/100, Loss: 0.780880374457552\n",
      "Epoch 65/100, Loss: 0.773009733986978\n",
      "Epoch 66/100, Loss: 0.7771196383886386\n",
      "Epoch 67/100, Loss: 0.7560851277465029\n",
      "Epoch 68/100, Loss: 0.7482699044627846\n",
      "Epoch 69/100, Loss: 0.757036786931784\n",
      "Epoch 70/100, Loss: 0.7422616392219622\n",
      "Epoch 71/100, Loss: 0.7391060938180419\n",
      "Epoch 72/100, Loss: 0.7379858635867815\n",
      "Epoch 73/100, Loss: 0.7282145781529382\n",
      "Epoch 74/100, Loss: 0.710724210646486\n",
      "Epoch 75/100, Loss: 0.7210693274446102\n",
      "Epoch 76/100, Loss: 0.7218305080974657\n",
      "Epoch 77/100, Loss: 0.7194660188620572\n",
      "Epoch 78/100, Loss: 0.7152969270481346\n",
      "Epoch 79/100, Loss: 0.707253766646657\n",
      "Epoch 80/100, Loss: 0.7076280361012474\n",
      "Epoch 81/100, Loss: 0.6957935953387324\n",
      "Epoch 82/100, Loss: 0.6825407763528083\n",
      "Epoch 83/100, Loss: 0.7013997602339236\n",
      "Epoch 84/100, Loss: 0.6953846171421091\n",
      "Epoch 85/100, Loss: 0.6650707365008833\n",
      "Epoch 86/100, Loss: 0.6805204412480093\n",
      "Epoch 87/100, Loss: 0.6873305327225225\n",
      "Epoch 88/100, Loss: 0.6854556928644526\n",
      "Epoch 89/100, Loss: 0.6811968520515324\n",
      "Epoch 90/100, Loss: 0.6522001505206904\n",
      "Epoch 91/100, Loss: 0.6538808410649473\n",
      "Epoch 92/100, Loss: 0.6545927790162477\n",
      "Epoch 93/100, Loss: 0.6457255000895169\n",
      "Epoch 94/100, Loss: 0.6505230821167249\n",
      "Epoch 95/100, Loss: 0.6460997910079561\n",
      "Epoch 96/100, Loss: 0.6473327793296755\n",
      "Epoch 97/100, Loss: 0.6366028059949529\n",
      "Epoch 98/100, Loss: 0.6511263628080102\n",
      "Epoch 99/100, Loss: 0.6398970461571155\n",
      "Epoch 100/100, Loss: 0.6394452696637168\n",
      "Test Loss: 1.7595019486485695\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs):\n",
    "    model.train()  # 设置为训练模式\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets)  # 注意 squeeze() 将输出从 (batch_size, 1) 变为 (batch_size)\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# 评估模型\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()  # 设置为评估模式\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Test Loss: {total_loss/len(test_loader)}\")\n",
    "\n",
    "# 检查是否有 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 模型训练\n",
    "train_model(model, train_loader, criterion, optimizer, device, epochs=50)\n",
    "\n",
    "# 模型评估\n",
    "evaluate_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f25c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    test_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for X_batch, y_batch in test_loader:  # 解包数据\n",
    "            # 将数据加载到设备\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            # 模型预测\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs.squeeze(), y_batch)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # 保存预测值和真实值，用于后续计算指标\n",
    "            all_predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "            all_targets.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    # 计算平均损失\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    \n",
    "    # 转换为 NumPy 数组\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    # 计算其他评估指标\n",
    "    mae = np.mean(np.abs(all_predictions - all_targets))  # 平均绝对误差\n",
    "    mse = np.mean((all_predictions - all_targets)**2)     # 均方误差\n",
    "    r2 = 1 - (np.sum((all_targets - all_predictions)**2) / np.sum((all_targets - np.mean(all_targets))**2))\n",
    "\n",
    "    return avg_loss, mae, mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2b81ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 1.7595\n",
      "Mean Absolute Error (MAE): 1.0012\n",
      "Mean Squared Error (MSE): 1.7483\n",
      "R² Score: 0.2259\n"
     ]
    }
   ],
   "source": [
    "# 训练完成后，评估模型\n",
    "test_loss, mae, mse, r2 = evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a5cf1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
